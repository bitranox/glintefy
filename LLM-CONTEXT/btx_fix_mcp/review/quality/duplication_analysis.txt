************* Module btx_fix_mcp.tools_venv
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.docs:[166:212]
==btx_fix_mcp.subservers.review.perf:[168:216]
            log_step(self.logger, 5, "Saving results")
            artifacts = self._save_results(results, all_issues)

            # Step 6: Generate summary
            summary = self._generate_summary(results, all_issues, python_files)

            # Determine status
            critical_count = len([i for i in all_issues if i.severity == "critical"])
            status = "SUCCESS" if critical_count == 0 else "PARTIAL"

            log_result(self.logger, status == "SUCCESS", f"Analysis complete: {len(all_issues)} issues found")

            return SubServerResult(
                status=status,
                summary=summary,
                artifacts=artifacts,
                metrics=self._compile_metrics(python_files, results, all_issues),
            )

        except Exception as e:
            log_error_detailed(
                self.logger,
                e,
                context={"repo_path": str(self.repo_path)},
                include_traceback=True,
            )
            return SubServerResult(
                status="FAILED",
                summary=f"# Documentation Analysis Failed\n\n**Error**: {e}",
                artifacts={},
                errors=[str(e)],
            )

    def _get_python_files(self) -> list[str]:
        """Get Python files to analyze."""
        files_list = self.input_dir / "files_code.txt"
        if not files_list.exists():
            files_list = self.input_dir / "files_to_review.txt"
        if not files_list.exists():
            return []
        all_files = files_list.read_text().strip().split("\n")
        python_files = [f for f in all_files if f.endswith(".py") and f]
        return [str(self.repo_path / f) for f in python_files]

    def _check_docstring_coverage(self) -> dict[str, Any]:
        """Check docstring coverage using interrogate.""" (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.docs:[402:432]
==btx_fix_mcp.subservers.review.perf:[406:436]
        critical_issues = [i.to_dict() for i in all_issues if i.severity == "critical"]
        warning_issues = [i.to_dict() for i in all_issues if i.severity == "warning"]

        verdict = evaluate_results(
            self.mindset,
            critical_issues,
            warning_issues,
            max(len(files), 1),
        )

        lines = [
            "# Documentation Analysis Report",
            "",
            "## Reviewer Mindset",
            "",
            self.mindset.format_header(),
            "",
            self.mindset.format_approach(),
            "",
            "## Verdict",
            "",
            f"**{verdict.verdict_text}**",
            "",
            f"- Critical issues: {verdict.critical_count}",
            f"- Warnings: {verdict.warning_count}",
            f"- Files analyzed: {len(files)}",
            "",
            "## Overview",
            "",
            f"**Files Analyzed**: {metrics['files_analyzed']}", (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.docs:[183:212]
==btx_fix_mcp.subservers.review.security:[226:259]
            )

        except Exception as e:
            log_error_detailed(
                self.logger,
                e,
                context={"repo_path": str(self.repo_path)},
                include_traceback=True,
            )
            return SubServerResult(
                status="FAILED",
                summary=f"# Security Analysis Failed\n\n**Error**: {e}",
                artifacts={},
                errors=[str(e)],
            )

    def _get_python_files(self) -> list[str]:
        """Get Python files to analyze."""
        files_list = self.input_dir / "files_code.txt"
        if not files_list.exists():
            files_list = self.input_dir / "files_to_review.txt"

        if not files_list.exists():
            return []

        all_files = files_list.read_text().strip().split("\n")
        python_files = [f for f in all_files if f.endswith(".py") and f]

        # Convert to absolute paths
        return [str(self.repo_path / f) for f in python_files]

    def _run_bandit(self, files: list[str]) -> list[dict[str, Any]]:
        """Run Bandit security scanner on files.""" (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.docs:[405:425]
==btx_fix_mcp.subservers.review.security:[364:384]
        verdict = evaluate_results(
            self.mindset,
            critical_issues,
            warning_issues,
            max(len(files), 1),
        )

        lines = [
            "# Documentation Analysis Report",
            "",
            "## Reviewer Mindset",
            "",
            self.mindset.format_header(),
            "",
            self.mindset.format_approach(),
            "",
            "## Verdict",
            "",
            f"**{verdict.verdict_text}**",
            "", (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.deps:[242:260]
==btx_fix_mcp.subservers.review.docs:[183:201]
            )

        except Exception as e:
            log_error_detailed(
                self.logger,
                e,
                context={"repo_path": str(self.repo_path)},
                include_traceback=True,
            )
            return SubServerResult(
                status="FAILED",
                summary=f"# Dependency Analysis Failed\n\n**Error**: {e}",
                artifacts={},
                errors=[str(e)],
            )

    def _detect_project_type(self) -> str | None:
        """Detect project type from dependency files.""" (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.perf:[185:203]
==btx_fix_mcp.subservers.review.quality.__init__:[245:260]
            )

        except Exception as e:
            log_error_detailed(
                self.logger,
                e,
                context={"repo_path": str(self.repo_path)},
                include_traceback=True,
            )
            return SubServerResult(
                status="FAILED",
                summary=f"# Quality Analysis Failed\n\n**Error**: {e}",
                artifacts={},
                errors=[str(e)],
            ) (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.report:[163:181]
==btx_fix_mcp.subservers.review.security:[226:244]
            )

        except Exception as e:
            log_error_detailed(
                self.logger,
                e,
                context={"repo_path": str(self.repo_path)},
                include_traceback=True,
            )
            return SubServerResult(
                status="FAILED",
                summary=f"# Security Analysis Failed\n\n**Error**: {e}",
                artifacts={},
                errors=[str(e)],
            )

    def _get_python_files(self) -> list[str]:
        """Get Python files to analyze.""" (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.docs:[66:85]
==btx_fix_mcp.subservers.review.perf:[71:90]
        base_config = get_config(start_dir=str(repo_path or Path.cwd()))
        output_base = base_config.get("review", {}).get("output_dir", "LLM-CONTEXT/btx_fix_mcp/review")

        if input_dir is None:
            input_dir = Path.cwd() / output_base / "scope"
        if output_dir is None:
            output_dir = Path.cwd() / output_base / name

        super().__init__(name=name, input_dir=input_dir, output_dir=output_dir)
        self.repo_path = repo_path or Path.cwd()
        self.mcp_mode = mcp_mode

        # Initialize logger
        if mcp_mode:
            self.logger = get_mcp_logger(f"btx_fix_mcp.{name}")
        else:
            self.logger = setup_logger(name, log_file=None, level=20)

        # Load config (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.docs:[69:85]
==btx_fix_mcp.subservers.review.quality.__init__:[114:132]
        if input_dir is None:
            input_dir = Path.cwd() / output_base / "scope"
        if output_dir is None:
            output_dir = Path.cwd() / output_base / name

        super().__init__(name=name, input_dir=input_dir, output_dir=output_dir)
        self.repo_path = repo_path or Path.cwd()
        self.mcp_mode = mcp_mode

        # Initialize logger based on mode
        if mcp_mode:
            # MCP mode: stderr only (MCP protocol uses stdout)
            self.logger = get_mcp_logger(f"btx_fix_mcp.{name}")
        else:
            # Standalone mode: stdout only (no file logging)
            self.logger = setup_logger(name, log_file=None, level=20)

        # Load config using extracted config module (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.__init__conf__:[61:71]
==scripts._utils:[585:595]
    fields = [
        ("name", name),
        ("title", title),
        ("version", version),
        ("homepage", homepage),
        ("author", author),
        ("author_email", author_email),
        ("shell_command", shell_command),
    ]
    pad = max(len(label) for label, _ in fields) (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.deps:[249:260]
==btx_fix_mcp.subservers.review.scope:[165:180]
                include_traceback=True,
            )
            return SubServerResult(
                status="FAILED",
                summary=f"# Scope Analysis Failed\n\n**Error**: {e}",
                artifacts={},
                errors=[str(e)],
            )

    def _find_git_files(self) -> list[Path]:
        """Find files from git uncommitted changes.

        Returns:
            List of file paths with uncommitted changes
        """ (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.docs:[457:468]
==btx_fix_mcp.subservers.review.perf:[461:472]
            lines.append("")

        # Approval status
        lines.extend(["## Approval Status", ""])
        lines.append(f"**{verdict.verdict_text}**")
        if verdict.recommendations:
            lines.append("")
            for rec in verdict.recommendations:
                lines.append(f"- {rec}")

        return "\n".join(lines) (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.docs:[201:212]
==btx_fix_mcp.subservers.review.quality.files:[40:56]
        files_list = self.input_dir / "files_code.txt"
        if not files_list.exists():
            files_list = self.input_dir / "files_to_review.txt"
        if not files_list.exists():
            return []
        all_files = files_list.read_text().strip().split("\n")
        python_files = [f for f in all_files if f.endswith(".py") and f]
        return [str(self.repo_path / f) for f in python_files]

    def _check_docstring_coverage(self) -> dict[str, Any]:
        """Check docstring coverage using interrogate.""" (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.quality.complexity:[34:46]
==btx_fix_mcp.subservers.review.quality.metrics:[31:43]
        }

    def _analyze_cyclomatic(self, files: list[str]) -> list[dict[str, Any]]:
        """Analyze cyclomatic complexity using radon."""
        results = []
        radon = str(get_tool_path("radon"))

        for file_path in files:
            if not Path(file_path).exists():
                continue
            try:
                result = subprocess.run( (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.docs:[101:114]
==btx_fix_mcp.subservers.review.perf:[107:120]
        missing = []

        # Check for files to analyze
        files_list = self.input_dir / "files_to_review.txt"
        if not files_list.exists():
            files_list = self.input_dir / "files_code.txt"
            if not files_list.exists():
                missing.append(f"No files list found in {self.input_dir}. Run scope sub-server first.")

        return len(missing) == 0, missing

    def execute(self) -> SubServerResult:
        """Execute performance analysis.""" (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.quality.complexity:[38:46]
==btx_fix_mcp.subservers.review.quality.metrics:[83:91]
        results = []
        radon = str(get_tool_path("radon"))

        for file_path in files:
            if not Path(file_path).exists():
                continue
            try:
                result = subprocess.run( (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.quality.complexity:[76:84]
==btx_fix_mcp.subservers.review.quality.metrics:[35:43]
        results = []
        radon = str(get_tool_path("radon"))

        for file_path in files:
            if not Path(file_path).exists():
                continue
            try:
                result = subprocess.run( (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.deps:[104:114]
==btx_fix_mcp.subservers.review.docs:[75:85]
        self.repo_path = repo_path or Path.cwd()
        self.mcp_mode = mcp_mode

        # Initialize logger
        if mcp_mode:
            self.logger = get_mcp_logger(f"btx_fix_mcp.{name}")
        else:
            self.logger = setup_logger(name, log_file=None, level=20)

        # Load config (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.docs:[377:387]
==btx_fix_mcp.subservers.review.perf:[384:394]
        if all_issues:
            path = self.output_dir / "issues.json"
            issues_dicts = [i.to_dict() for i in all_issues]
            path.write_text(json.dumps(issues_dicts, indent=2))
            artifacts["issues"] = path

        return artifacts

    def _compile_metrics(self, files: list[str], results: dict[str, Any], all_issues: list[BaseIssue]) -> dict[str, Any]:
        """Compile metrics for result.""" (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.docs:[101:110]
==btx_fix_mcp.subservers.review.security:[146:156]
        missing = []

        # Check for files to analyze
        files_list = self.input_dir / "files_to_review.txt"
        if not files_list.exists():
            files_list = self.input_dir / "files_code.txt"
            if not files_list.exists():
                missing.append(f"No files list found in {self.input_dir}. Run scope sub-server first.")
 (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.docs:[461:468]
==btx_fix_mcp.subservers.review.security:[461:468]
        lines.append(f"**{verdict.verdict_text}**")
        if verdict.recommendations:
            lines.append("")
            for rec in verdict.recommendations:
                lines.append(f"- {rec}")

        return "\n".join(lines) (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.perf:[136:144]
==btx_fix_mcp.subservers.review.quality.__init__:[184:191]
                return SubServerResult(
                    status="SUCCESS",
                    summary="# Quality Analysis\n\nNo files to analyze.",
                    artifacts={},
                    metrics={"files_analyzed": 0},
                )
 (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.quality.architecture:[45:51]
==btx_fix_mcp.subservers.review.quality.complexity:[109:116]
        for file_path in files:
            if not Path(file_path).exists():
                continue
            try:
                content = Path(file_path).read_text(encoding="utf-8", errors="ignore")
                tree = ast.parse(content) (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.quality.architecture:[98:104]
==btx_fix_mcp.subservers.review.quality.complexity:[160:167]
        for file_path in files:
            if not Path(file_path).exists():
                continue
            try:
                content = Path(file_path).read_text(encoding="utf-8", errors="ignore")
                tree = ast.parse(content) (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.quality.complexity:[47:53]
==btx_fix_mcp.subservers.review.quality.metrics:[44:50]
                    capture_output=True,
                    text=True,
                    timeout=30,
                )
                if result.returncode == 0 and result.stdout.strip():
                    data = json.loads(result.stdout) (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.quality.complexity:[85:91]
==btx_fix_mcp.subservers.review.quality.metrics:[92:98]
                    capture_output=True,
                    text=True,
                    timeout=30,
                )
                if result.returncode == 0 and result.stdout.strip():
                    data = json.loads(result.stdout) (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.quality.static:[69:75]
==btx_fix_mcp.subservers.review.quality.types:[47:55]
                capture_output=True,
                text=True,
                timeout=120,
            )
            results["raw_output"] = result.stdout + result.stderr
            for line in result.stdout.split("\n"): (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.deps:[590:596]
==btx_fix_mcp.subservers.review.quality.summary:[225:230]
    if verdict.recommendations:
        lines.append("")
        for rec in verdict.recommendations:
            lines.append(f"- {rec}")
    return lines (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.deps:[105:114]
==btx_fix_mcp.subservers.review.scope:[73:89]
        self.mcp_mode = mcp_mode

        # Setup logging based on mode
        if mcp_mode:
            # MCP mode: stderr only (MCP protocol uses stdout)
            self.logger = get_mcp_logger(f"btx_fix_mcp.{name}")
        else:
            # Standalone mode: stdout only (no file logging)
            self.logger = setup_logger(name, log_file=None, level=20)  # INFO

    def validate_inputs(self) -> tuple[bool, list[str]]:
        """Validate inputs for scope analysis.

        Returns:
            Tuple of (valid, missing_items)
        """ (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.docs:[101:108]
==btx_fix_mcp.subservers.review.quality.files:[24:29]
        missing = []
        files_list = self.input_dir / "files_to_review.txt"
        if not files_list.exists():
            files_list = self.input_dir / "files_code.txt"
            if not files_list.exists(): (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.docs:[71:79]
==btx_fix_mcp.subservers.review.report:[100:106]
        if output_dir is None:
            output_dir = Path.cwd() / output_base / name

        super().__init__(name=name, input_dir=input_dir, output_dir=output_dir)
        self.repo_path = repo_path or Path.cwd()
        self.mcp_mode = mcp_mode (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.quality.complexity:[72:84]
==btx_fix_mcp.subservers.review.quality.metrics:[79:91]
        return results

    def _analyze_maintainability(self, files: list[str]) -> list[dict[str, Any]]:
        """Analyze maintainability index using radon."""
        results = []
        radon = str(get_tool_path("radon"))

        for file_path in files:
            if not Path(file_path).exists():
                continue
            try:
                result = subprocess.run( (duplicate-code)
src/btx_fix_mcp/tools_venv.py:1:0: R0801: Similar lines in 2 files
==btx_fix_mcp.subservers.review.report:[109:119]
==btx_fix_mcp.subservers.review.scope:[76:92]
        if mcp_mode:
            self.logger = get_mcp_logger(f"btx_fix_mcp.{name}")
        else:
            self.logger = setup_logger(name, log_file=None, level=20)

    def validate_inputs(self) -> tuple[bool, list[str]]:
        """Validate inputs for report generation."""
        missing = []

        # Check that at least one sub-server has run (duplicate-code)

------------------------------------------------------------------
Your code has been rated at 9.93/10 (previous run: 9.93/10, +0.00)

